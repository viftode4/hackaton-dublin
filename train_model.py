"""
GridSync ‚Äî Regression Model Training

Step-by-step:
  1. Load the feature matrix (from analyze_features.py output)
  2. Select top correlated features
  3. Train Ridge Regression with Leave-One-Out cross-validation
  4. Compare against the naive baseline (country_ci only)
  5. Export the trained model coefficients for use in geo_estimator.py

Run: python3 train_model.py
Requires: feature_analysis.csv (generated by analyze_features.py)
"""

import json
import math
import warnings
warnings.filterwarnings('ignore')

import numpy as np
import pandas as pd
from sklearn.linear_model import Ridge, LinearRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import LeaveOneOut, cross_val_predict


def main():
    # ================================================================
    # STEP 1: Load the feature matrix
    # ================================================================
    print("=" * 65)
    print("STEP 1: Load feature matrix")
    print("=" * 65)
    df = pd.read_csv("feature_analysis.csv")
    print(f"  Loaded {len(df)} samples √ó {len(df.columns)} columns")
    print(f"  Ground truth range: {df['ground_truth_ci'].min():.0f} ‚Äì {df['ground_truth_ci'].max():.0f} gCO‚ÇÇ/kWh")
    print(f"  Mean: {df['ground_truth_ci'].mean():.0f}, Std: {df['ground_truth_ci'].std():.0f}")

    # ================================================================
    # STEP 2: Define feature sets to compare
    # ================================================================
    print(f"\n{'=' * 65}")
    print("STEP 2: Define candidate feature sets")
    print("=" * 65)

    feature_sets = {
        "Baseline (country_ci only)": [
            "country_ci",
        ],
        "Model A (country + TRACE top 2)": [
            "country_ci",
            "emissions_per_capacity",
            "local_pct_coal",
        ],
        "Model A+ (country + TRACE + renewables)": [
            "country_ci",
            "emissions_per_capacity",
            "local_pct_coal",
            "local_pct_clean",
        ],
        "Model A++ (A+ + idw_weighted_ci)": [
            "country_ci",
            "emissions_per_capacity",
            "local_pct_coal",
            "local_pct_clean",
            "idw_weighted_ci",
        ],
        "Model A+++ (A++ + country_ci¬≤)": [
            "country_ci",
            "emissions_per_capacity",
            "local_pct_coal",
            "local_pct_clean",
            "idw_weighted_ci",
            "country_ci_sq",
        ],
        "Model E (A+ + emaps_zone_ci)": [
            "country_ci",
            "emissions_per_capacity",
            "local_pct_coal",
            "local_pct_clean",
            "emaps_zone_ci",
        ],
        "Model E+ (A+++ + emaps_zone_ci)": [
            "country_ci",
            "emissions_per_capacity",
            "local_pct_coal",
            "local_pct_clean",
            "idw_weighted_ci",
            "country_ci_sq",
            "emaps_zone_ci",
        ],
        "Model E++ (E+ + emaps_idw_ci)": [
            "country_ci",
            "emissions_per_capacity",
            "local_pct_coal",
            "local_pct_clean",
            "idw_weighted_ci",
            "country_ci_sq",
            "emaps_idw_ci",
        ],
        "Model B (country + TRACE top 4)": [
            "country_ci",
            "emissions_per_capacity",
            "local_pct_coal",
            "mean_emissions_per_plant",
            "abs_lat",
        ],
        "Model B+ (top 4 + renewables)": [
            "country_ci",
            "emissions_per_capacity",
            "local_pct_coal",
            "local_pct_clean",
            "mean_emissions_per_plant",
            "abs_lat",
        ],
        "Model C (all strong features)": [
            "country_ci",
            "emissions_per_capacity",
            "local_pct_coal",
            "mean_emissions_per_plant",
            "abs_lat",
            "idw_weighted_ci",
            "total_emissions_300km",
            "local_pct_fossil",
        ],
        "Model D (TRACE only, no country)": [
            "emissions_per_capacity",
            "local_pct_coal",
            "mean_emissions_per_plant",
            "abs_lat",
            "idw_weighted_ci",
            "total_emissions_300km",
            "local_pct_fossil",
        ],
        # ‚îÄ‚îÄ Fraction-based models ‚îÄ‚îÄ
        "Model F (fractions only)": [
            "country_fossil_frac",
            "country_clean_frac",
            "country_coal_frac",
            "country_nuclear_frac",
        ],
        "Model F+ (fractions + local TRACE)": [
            "country_fossil_frac",
            "country_clean_frac",
            "country_coal_frac",
            "country_nuclear_frac",
            "local_pct_coal",
            "local_pct_clean",
        ],
        "Model G (fractions + normalized CI)": [
            "country_fossil_frac",
            "country_clean_frac",
            "ct_grid_ci_est",
            "local_pct_coal",
            "local_pct_clean",
        ],
        "Model G+ (G + emaps)": [
            "country_fossil_frac",
            "country_clean_frac",
            "ct_grid_ci_est",
            "local_pct_coal",
            "local_pct_clean",
            "emaps_idw_ci",
        ],
        "Model H (best of both: ci + fractions)": [
            "country_ci",
            "country_fossil_frac",
            "country_clean_frac",
            "ct_grid_ci_est",
            "local_pct_coal",
            "local_pct_clean",
        ],
        "Model H+ (H + emaps)": [
            "country_ci",
            "country_fossil_frac",
            "country_clean_frac",
            "ct_grid_ci_est",
            "local_pct_coal",
            "local_pct_clean",
            "emaps_idw_ci",
        ],
        # ‚îÄ‚îÄ Regional plant-level features (from CT emissions_factor, activity, other5) ‚îÄ‚îÄ
        "Model R (local EF weighted)": [
            "local_ef_weighted",
            "local_mean_cf",
            "local_generation_gwh",
        ],
        "Model R+ (R + country_ci)": [
            "country_ci",
            "local_ef_weighted",
            "local_mean_cf",
        ],
        "Model R++ (R+ + pct)": [
            "country_ci",
            "local_ef_weighted",
            "local_mean_cf",
            "local_pct_coal",
            "local_pct_clean",
        ],
        # ‚îÄ‚îÄ Zone capacity features (from eMaps installed MW per fuel) ‚îÄ‚îÄ
        "Model Z (zone cap fracs)": [
            "emaps_zone_clean_cap_frac",
            "emaps_zone_fossil_cap_frac",
            "emaps_zone_coal_cap_mw",
        ],
        "Model Z+ (zone cap + country_ci)": [
            "country_ci",
            "emaps_zone_clean_cap_frac",
            "emaps_zone_fossil_cap_frac",
        ],
        # ‚îÄ‚îÄ Best hybrid: combine all regional signals ‚îÄ‚îÄ
        "Model BEST (all regional)": [
            "country_ci",
            "local_ef_weighted",
            "local_pct_coal",
            "local_pct_clean",
            "emaps_zone_fossil_cap_frac",
        ],
        "Model BEST+ (regional + emaps CI)": [
            "country_ci",
            "local_ef_weighted",
            "local_pct_coal",
            "local_pct_clean",
            "emaps_idw_ci",
            "emaps_zone_fossil_cap_frac",
        ],
    }

    for name, feats in feature_sets.items():
        print(f"\n  {name}:")
        for f in feats:
            print(f"    ‚Ä¢ {f}")

    # ================================================================
    # STEP 3: Train and cross-validate each model
    # ================================================================
    print(f"\n{'=' * 65}")
    print("STEP 3: Train Ridge Regression with LOO cross-validation")
    print("=" * 65)
    print("\n  LOO = Leave-One-Out: train on 38 samples, predict 1, repeat 39 times")
    print("  This gives unbiased error estimates for each model.\n")

    y = df['ground_truth_ci'].values
    loo = LeaveOneOut()
    results = {}
    best_model = None
    best_mae = float('inf')

    for name, feats in feature_sets.items():
        # Drop rows with NaN in selected features
        subset = df[['ground_truth_ci'] + feats].dropna()
        if len(subset) < 10:
            print(f"  {name}: SKIPPED (only {len(subset)} complete samples)")
            continue

        X = subset[feats].values
        y_sub = subset['ground_truth_ci'].values

        # Standardize features
        scaler = StandardScaler()
        X_scaled = scaler.fit_transform(X)

        # Ridge regression with LOO cross-validation
        model = Ridge(alpha=1.0)
        y_pred = cross_val_predict(model, X_scaled, y_sub, cv=LeaveOneOut())

        # Metrics
        errors = y_sub - y_pred
        abs_errors = np.abs(errors)
        mae = abs_errors.mean()
        rmse = np.sqrt((errors ** 2).mean())
        mape = (abs_errors / np.maximum(y_sub, 1) * 100).mean()
        r2 = 1 - (errors ** 2).sum() / ((y_sub - y_sub.mean()) ** 2).sum()

        results[name] = {
            "n_features": len(feats), "n_samples": len(subset),
            "mae": mae, "rmse": rmse, "mape": mape, "r2": r2,
            "y_true": y_sub, "y_pred": y_pred, "features": feats,
        }

        improvement = ""
        if "Baseline" in list(results.keys()):
            baseline_mae = results[list(results.keys())[0]]["mae"]
            pct = (baseline_mae - mae) / baseline_mae * 100
            improvement = f"  ({pct:+.1f}% vs baseline)" if pct != 0 else ""

        emoji = "üèÜ" if mae < best_mae else "  "
        if mae < best_mae:
            best_mae = mae
            best_model = name

        print(f"  {emoji} {name}")
        print(f"     Features: {len(feats)} | Samples: {len(subset)}")
        print(f"     MAE:  {mae:6.1f} gCO‚ÇÇ/kWh{improvement}")
        print(f"     RMSE: {rmse:6.1f} gCO‚ÇÇ/kWh")
        print(f"     MAPE: {mape:6.1f}%")
        print(f"     R¬≤:   {r2:6.3f}")
        print()

    # ================================================================
    # STEP 4: Compare all models
    # ================================================================
    print(f"{'=' * 65}")
    print("STEP 4: Model comparison summary")
    print("=" * 65)
    print(f"\n  {'Model':<40} {'MAE':>6} {'RMSE':>7} {'R¬≤':>6} {'Feats':>5}")
    print("  " + "-" * 66)
    for name, r in results.items():
        marker = " üèÜ" if name == best_model else ""
        print(f"  {name:<40} {r['mae']:>6.1f} {r['rmse']:>7.1f} {r['r2']:>6.3f} {r['n_features']:>5}{marker}")

    baseline_mae = results[list(results.keys())[0]]["mae"]
    best_r = results[best_model]
    print(f"\n  Baseline MAE: {baseline_mae:.1f} gCO‚ÇÇ/kWh")
    print(f"  Best model:   {best_model}")
    print(f"  Best MAE:     {best_r['mae']:.1f} gCO‚ÇÇ/kWh")
    print(f"  Improvement:  {(baseline_mae - best_r['mae']):.1f} gCO‚ÇÇ/kWh ({(baseline_mae - best_r['mae'])/baseline_mae*100:.1f}%)")

    # ================================================================
    # STEP 5: Train final model and export coefficients
    # ================================================================
    print(f"\n{'=' * 65}")
    print(f"STEP 5: Train final model ({best_model})")
    print("=" * 65)

    best_feats = results[best_model]["features"]
    subset = df[['ground_truth_ci', 'region'] + best_feats].dropna()
    X_final = subset[best_feats].values
    y_final = subset['ground_truth_ci'].values

    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_final)

    model = Ridge(alpha=1.0)
    model.fit(X_scaled, y_final)

    print(f"\n  Coefficients (standardized):")
    print(f"  {'Feature':<35} {'Coeff':>8} {'|Coeff|':>8} {'Direction':<15}")
    print("  " + "-" * 70)
    coefs = list(zip(best_feats, model.coef_))
    coefs_sorted = sorted(coefs, key=lambda x: abs(x[1]), reverse=True)
    for feat, coef in coefs_sorted:
        direction = "‚Üë dirtier" if coef > 0 else "‚Üì cleaner"
        print(f"  {feat:<35} {coef:>+8.2f} {abs(coef):>8.2f} {direction}")
    print(f"  {'intercept':<35} {model.intercept_:>+8.2f}")

    # ================================================================
    # STEP 6: Show per-sample predictions
    # ================================================================
    print(f"\n{'=' * 65}")
    print("STEP 6: Per-sample predictions (LOO)")
    print("=" * 65)

    y_pred_final = cross_val_predict(model, X_scaled, y_final, cv=LeaveOneOut())
    pred_df = pd.DataFrame({
        'region': subset['region'].values,
        'actual': y_final,
        'predicted': np.round(y_pred_final, 1),
        'error': np.round(y_pred_final - y_final, 1),
        'abs_error': np.round(np.abs(y_pred_final - y_final), 1),
    }).sort_values('abs_error', ascending=False)

    print(f"\n  {'Region':<35} {'Actual':>7} {'Pred':>7} {'Error':>7}")
    print("  " + "-" * 58)
    for _, r in pred_df.iterrows():
        emoji = "‚ùå" if abs(r['error']) > 100 else "‚ö†Ô∏è" if abs(r['error']) > 50 else "‚úÖ"
        print(f"  {emoji} {r['region']:<33} {r['actual']:>7.0f} {r['predicted']:>7.1f} {r['error']:>+7.1f}")

    # ================================================================
    # STEP 7: Export model for use in geo_estimator.py
    # ================================================================
    print(f"\n{'=' * 65}")
    print("STEP 7: Export model coefficients")
    print("=" * 65)

    model_config = {
        "model_type": "ridge_regression",
        "alpha": 1.0,
        "features": best_feats,
        "scaler_mean": scaler.mean_.tolist(),
        "scaler_scale": scaler.scale_.tolist(),
        "coefficients": model.coef_.tolist(),
        "intercept": float(model.intercept_),
        "training_samples": len(subset),
        "loo_mae": float(results[best_model]["mae"]),
        "loo_r2": float(results[best_model]["r2"]),
    }

    with open("trained_model.json", "w") as f:
        json.dump(model_config, f, indent=2)

    print(f"\n  ‚úÖ Model saved to trained_model.json")
    print(f"  Features: {best_feats}")
    print(f"  LOO MAE: {results[best_model]['mae']:.1f} gCO‚ÇÇ/kWh")
    print(f"  LOO R¬≤:  {results[best_model]['r2']:.3f}")
    print(f"\n  To use in geo_estimator.py:")
    print(f"    1. Load trained_model.json")
    print(f"    2. Extract the {len(best_feats)} features for any location")
    print(f"    3. Standardize: (x - mean) / scale")
    print(f"    4. Predict: dot(coefficients, x_scaled) + intercept")


if __name__ == "__main__":
    main()
